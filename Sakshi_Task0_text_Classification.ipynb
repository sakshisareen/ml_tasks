{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "This task tests your ability to solve a real-world problem using the concepts learned in Text Classification module.\n",
    "Create a benchmark analysis with different algorithms and feature extractors.\n",
    "\n",
    "Dataset: Fetch 20 Newsgroups (same as in class work)​\n",
    "\n",
    "Algorithms: Multinomial Naïve Bayes, Logistic Regression, Support Vector Machines, Decision Trees​\n",
    "\n",
    "Feature Extractors: CountVectorizer, Word2Vec, Doc2Vec and so on​\n",
    "\n",
    "​\n",
    "\n",
    "Benchmark all the possible above configurations and choose the best algorithm and feature extractor amongst all configurations​ and put it in a .txt or .doc file in a tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from gensim import models\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(newsgroups.data, newsgroups.target, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\n",
    "   # (\"Multinomial Naïve Bayes\", MultinomialNB()),\n",
    "    (\"Logistic Regression\", LogisticRegression(max_iter=1000)),\n",
    "    (\"Support Vector Machines\", SVC()),\n",
    "    (\"Decision Trees\", DecisionTreeClassifier())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractors = [\n",
    "   # (\"CountVectorizer\", CountVectorizer()),\n",
    "    (\"Word2Vec\",Word2Vec()),\n",
    "    (\"Doc2Vec\",Doc2Vec())\n",
    "#\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sakshi/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for algorithm_name, algorithm in algorithms:\n",
    "    for feature_extractor_name, feature_extractor in feature_extractors:\n",
    "        # Prepare the data using the feature extractor\n",
    "        if feature_extractor_name == \"CountVectorizer\":\n",
    "            X_train_transformed = feature_extractor.fit_transform(X_train)\n",
    "            X_test_transformed = feature_extractor.transform(X_test)\n",
    "        elif feature_extractor_name == \"Word2Vec\":\n",
    "            tokenized_X_train = [simple_preprocess(text) for text in X_train]\n",
    "            tokenized_X_test = [simple_preprocess(text) for text in X_test]\n",
    "            model = Word2Vec(sentences=tokenized_X_train, vector_size=100, window=5, min_count=1, sg=0)\n",
    "            X_train_transformed = np.array([np.mean([model.wv[word] for word in words if word in model.wv] or [np.zeros(100)], axis=0) for words in tokenized_X_train])\n",
    "            X_test_transformed = np.array([np.mean([model.wv[word] for word in words if word in model.wv] or [np.zeros(100)], axis=0) for words in tokenized_X_test])\n",
    "        elif feature_extractor_name == \"Doc2Vec\":\n",
    "            tokenized_X_train = [simple_preprocess(text) for text in X_train]\n",
    "            tokenized_X_test = [simple_preprocess(text) for text in X_test]\n",
    "            tagged_data = [TaggedDocument(words=words, tags=[str(i)]) for i, words in enumerate(tokenized_X_train)]\n",
    "            model = Doc2Vec(vector_size=100, window=2, min_count=1, workers=4, epochs=30)\n",
    "            model.build_vocab(tagged_data)\n",
    "            model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "            X_train_transformed = np.array([model.dv[i] for i in range(len(tokenized_X_train))])\n",
    "            X_test_transformed = np.array([model.infer_vector(words) for words in tokenized_X_test])\n",
    "            X_test_transformed = preprocessing.normalize(X_test_transformed)\n",
    "\n",
    "        # Fit the model and make predictions\n",
    "        algorithm.fit(X_train_transformed, y_train)\n",
    "        y_pred = algorithm.predict(X_test_transformed)\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='macro')\n",
    "        recall = recall_score(y_test, y_pred, average='macro')\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "        results.append((algorithm_name, feature_extractor_name, accuracy, precision, recall, f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: Multinomial Naïve Bayes, Feature Extractor: CountVectorizer\n",
      "Accuracy: 0.62, Precision: 0.68, Recall: 0.60, F1-Score: 0.59\n",
      "----------------------------------------------------\n",
      "Algorithm: Logistic Regression, Feature Extractor: CountVectorizer\n",
      "Accuracy: 0.68, Precision: 0.68, Recall: 0.67, F1-Score: 0.68\n",
      "----------------------------------------------------\n",
      "Algorithm: Support Vector Machines, Feature Extractor: CountVectorizer\n",
      "Accuracy: 0.12, Precision: 0.50, Recall: 0.12, F1-Score: 0.10\n",
      "----------------------------------------------------\n",
      "Algorithm: Decision Trees, Feature Extractor: CountVectorizer\n",
      "Accuracy: 0.48, Precision: 0.47, Recall: 0.46, F1-Score: 0.47\n",
      "----------------------------------------------------\n",
      "Algorithm: Logistic Regression, Feature Extractor: Word2Vec\n",
      "Accuracy: 0.46, Precision: 0.45, Recall: 0.45, F1-Score: 0.44\n",
      "----------------------------------------------------\n",
      "Algorithm: Logistic Regression, Feature Extractor: Doc2Vec\n",
      "Accuracy: 0.51, Precision: 0.62, Recall: 0.49, F1-Score: 0.47\n",
      "----------------------------------------------------\n",
      "Algorithm: Support Vector Machines, Feature Extractor: Word2Vec\n",
      "Accuracy: 0.45, Precision: 0.43, Recall: 0.43, F1-Score: 0.43\n",
      "----------------------------------------------------\n",
      "Algorithm: Support Vector Machines, Feature Extractor: Doc2Vec\n",
      "Accuracy: 0.12, Precision: 0.41, Recall: 0.11, F1-Score: 0.10\n",
      "----------------------------------------------------\n",
      "Algorithm: Decision Trees, Feature Extractor: Word2Vec\n",
      "Accuracy: 0.22, Precision: 0.22, Recall: 0.22, F1-Score: 0.22\n",
      "----------------------------------------------------\n",
      "Algorithm: Decision Trees, Feature Extractor: Doc2Vec\n",
      "Accuracy: 0.10, Precision: 0.10, Recall: 0.10, F1-Score: 0.09\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for algorithm_name, feature_extractor_name, accuracy, precision, recall, f1 in results:\n",
    "    print(f\"Algorithm: {algorithm_name}, Feature Extractor: {feature_extractor_name}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}\")\n",
    "    print(\"----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
